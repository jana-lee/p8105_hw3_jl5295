p8105\_hw3\_jl5295
================
Jana Lee
10/7/2019

## Problem 1: Instacart

Load the data for Instacart and Exploration of Aisles

``` r
data("instacart")

number_aisles = 
  instacart %>% 
  count(aisle) %>% 
  arrange(desc(n)) %>% 
  view()
```

**Description of Dataset:** In the `instacart` dataset, there are
1,384,617 observations and 15 variables. There are 15 columns in the
dataset. Some key variables in this dataset include `product_name`,
`order_hour_of_day`, and `add_to_cart_order`.

**How many aisles are there, and which aisles are the most items ordered
from?** There are 134 unique aisles. The tope 3 aisles most ordered from
are, from most ordered to least: “fresh vegetables” (150,609 orders),
“fresh fruits” (150,473 orders), and “packaged vegetables
fruits”(78,493 orders).

Aisle Plot

``` r
aisle_plot = 
  filter(number_aisles, n > 10000)

ggplot(aisle_plot, aes(
    x = reorder(aisle, -n), 
    y = n)) +
  geom_point(aes(color = n)) +
  theme (axis.text.x = element_text(angle = 90, hjust = 1),
         axis.text = element_text(size=8)) +
  labs (
    title = "Plot of Number of Items in Each Aisle for Over 10,000 Items Ordered ",
    x = "Aisle",
    y = "Count of Items Ordered")
```

<img src="p8105_hw3_jl5295_files/figure-gfm/unnamed-chunk-2-1.png" width="90%" />
*Please note that plot is ordered by most number of orders in each aisle
to least to least number of orders in each aisle.*

Table Showing 3 Most Popular Items

``` r
table_pop_items = instacart %>% 
  filter(
    aisle == "baking ingredients" | 
    aisle == "dog food care" | 
    aisle == "packaged vegetables fruits") %>% 
  group_by(aisle, product_name) %>% 
  summarize (n = n()) %>% 
  mutate (top_three = min_rank(desc(n))) %>% 
  filter (top_three <= 3)
  
table_pop_items %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | top\_three |
| :------------------------- | :-------------------------------------------- | ---: | ---------: |
| baking ingredients         | Cane Sugar                                    |  336 |          3 |
| baking ingredients         | Light Brown Sugar                             |  499 |          1 |
| baking ingredients         | Pure Baking Soda                              |  387 |          2 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |          2 |
| dog food care              | Small Dog Biscuits                            |   26 |          3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |          1 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |          1 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |          3 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |          2 |

Table Showing Pink Lady Apples and Coffee Ice Cream Orders

``` r
table_apples_coffee = instacart %>% 
  filter(
    product_name == "Pink Lady Apples" | 
    product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    mean_order = round(mean(order_hour_of_day), digits = 0)) %>% 
  pivot_wider(
   names_from = "order_dow" , 
   values_from = "mean_order")  %>% 
  rename(
    "Sunday" = "0", 
    "Monday" = "1", 
    "Tuesday" = "2", 
    "Wednesday" = "3", 
    "Thursday" = "4", 
    "Friday" = "5", 
    "Saturday" = "6") %>% 
  rename ("Product Name" = product_name)

table_apples_coffee %>% 
  knitr::kable()
```

| Product Name     | Sunday | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday |
| :--------------- | -----: | -----: | ------: | --------: | -------: | -----: | -------: |
| Coffee Ice Cream |     14 |     14 |      15 |        15 |       15 |     12 |       14 |
| Pink Lady Apples |     13 |     11 |      12 |        14 |       12 |     13 |       12 |

## Problem 2: BRFSS

Loading & Data Cleaning:

``` r
data("brfss_smart2010")

brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(
    topic == "Overall Health" |
    response == "Poor" | 
    response == "Fair" |
    response == "Very Good" |
    response == "Excellent") %>%
  select(-location_id, -data_value_footnote_symbol, -data_value_footnote) %>% 
  mutate(response = ordered(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) 

brfss
```

    ## # A tibble: 10,625 x 20
    ##     year locationabbr locationdesc class topic question response
    ##    <int> <chr>        <chr>        <chr> <chr> <chr>    <ord>   
    ##  1  2010 AL           AL - Jeffer… Heal… Over… How is … Excelle…
    ##  2  2010 AL           AL - Jeffer… Heal… Over… How is … Very go…
    ##  3  2010 AL           AL - Jeffer… Heal… Over… How is … Good    
    ##  4  2010 AL           AL - Jeffer… Heal… Over… How is … Fair    
    ##  5  2010 AL           AL - Jeffer… Heal… Over… How is … Poor    
    ##  6  2010 AL           AL - Mobile… Heal… Over… How is … Excelle…
    ##  7  2010 AL           AL - Mobile… Heal… Over… How is … Very go…
    ##  8  2010 AL           AL - Mobile… Heal… Over… How is … Good    
    ##  9  2010 AL           AL - Mobile… Heal… Over… How is … Fair    
    ## 10  2010 AL           AL - Mobile… Heal… Over… How is … Poor    
    ## # … with 10,615 more rows, and 13 more variables: sample_size <int>,
    ## #   data_value <dbl>, confidence_limit_low <dbl>,
    ## #   confidence_limit_high <dbl>, display_order <int>,
    ## #   data_value_unit <chr>, data_value_type <chr>, data_source <chr>,
    ## #   class_id <chr>, topic_id <chr>, question_id <chr>, respid <chr>,
    ## #   geo_location <chr>

In 2002, which states were observed at 7 or more locations? What about
in 2010?

``` r
states_2002 = brfss %>% 
  filter (year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarize(
    number_obs = n_distinct(geo_location)) %>% 
  filter(number_obs >= 7) %>% 
  rename("states" = locationabbr)

states_2010 = brfss %>% 
  filter (year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarize(
    number_obs = n_distinct(geo_location)) %>% 
  filter(number_obs >= 7) %>% 
  rename("states" = locationabbr)
```

In 2002, six states were observed at 7 or more locations: CT, FL, MA,
NC, NJ, and PA. In 2010, fourteen states were observed at 7 or more
locations: CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC,TX, WA.

Make Excellent Dataset:

``` r
excellent_data = brfss %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_value = round(mean(data_value, na.rm = TRUE), digits = 2)) %>% 
  rename("state" = locationabbr)
```

Spaghetti Plot:

``` r
spaghetti_plot = excellent_data %>% 
  ggplot(aes(x = year, y = mean_value, color = state)) +
  geom_line() +
  labs(
    title = "Spaghetti Plot of Average Value Over Time in 50 States",
    x = "Year",
    y = "Average Data Values"
  )

spaghetti_plot
```

<img src="p8105_hw3_jl5295_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

## Problem 3: Accelerometers

Loading, tidying, and wrangling the data

Your final dataset should include all originally observed variables and
values; have useful variable names; include a weekday vs weekend
variable; and encode data with reasonable variable classes. Describe the
resulting dataset (e.g. what variables exist, how many observations,
etc).

``` r
prob_3 = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    day = factor(day, labels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
    day_of_week = day == "Saturday" | day == "Sunday",
    day_of_week = ifelse(day_of_week == TRUE, "Weekend", "Weekday"))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
prob_3
```

    ## # A tibble: 35 x 1,444
    ##     week day_id day   activity_1 activity_2 activity_3 activity_4
    ##    <dbl>  <dbl> <fct>      <dbl>      <dbl>      <dbl>      <dbl>
    ##  1     1      1 Mond…       88.4       82.2       64.4       70.0
    ##  2     1      2 Tues…        1          1          1          1  
    ##  3     1      3 Wedn…        1          1          1          1  
    ##  4     1      4 Thur…        1          1          1          1  
    ##  5     1      5 Frid…       47.4       48.8       46.9       35.8
    ##  6     1      6 Satu…       64.8       59.5       73.7       45.7
    ##  7     1      7 Sund…       71.1      103.        68.5       45.4
    ##  8     2      8 Mond…      675        542       1010        779  
    ##  9     2      9 Tues…      291        335        393        335  
    ## 10     2     10 Wedn…       64         11          1          1  
    ## # … with 25 more rows, and 1,437 more variables: activity_5 <dbl>,
    ## #   activity_6 <dbl>, activity_7 <dbl>, activity_8 <dbl>,
    ## #   activity_9 <dbl>, activity_10 <dbl>, activity_11 <dbl>,
    ## #   activity_12 <dbl>, activity_13 <dbl>, activity_14 <dbl>,
    ## #   activity_15 <dbl>, activity_16 <dbl>, activity_17 <dbl>,
    ## #   activity_18 <dbl>, activity_19 <dbl>, activity_20 <dbl>,
    ## #   activity_21 <dbl>, activity_22 <dbl>, activity_23 <dbl>,
    ## #   activity_24 <dbl>, activity_25 <dbl>, activity_26 <dbl>,
    ## #   activity_27 <dbl>, activity_28 <dbl>, activity_29 <dbl>,
    ## #   activity_30 <dbl>, activity_31 <dbl>, activity_32 <dbl>,
    ## #   activity_33 <dbl>, activity_34 <dbl>, activity_35 <dbl>,
    ## #   activity_36 <dbl>, activity_37 <dbl>, activity_38 <dbl>,
    ## #   activity_39 <dbl>, activity_40 <dbl>, activity_41 <dbl>,
    ## #   activity_42 <dbl>, activity_43 <dbl>, activity_44 <dbl>,
    ## #   activity_45 <dbl>, activity_46 <dbl>, activity_47 <dbl>,
    ## #   activity_48 <dbl>, activity_49 <dbl>, activity_50 <dbl>,
    ## #   activity_51 <dbl>, activity_52 <dbl>, activity_53 <dbl>,
    ## #   activity_54 <dbl>, activity_55 <dbl>, activity_56 <dbl>,
    ## #   activity_57 <dbl>, activity_58 <dbl>, activity_59 <dbl>,
    ## #   activity_60 <dbl>, activity_61 <dbl>, activity_62 <dbl>,
    ## #   activity_63 <dbl>, activity_64 <dbl>, activity_65 <dbl>,
    ## #   activity_66 <dbl>, activity_67 <dbl>, activity_68 <dbl>,
    ## #   activity_69 <dbl>, activity_70 <dbl>, activity_71 <dbl>,
    ## #   activity_72 <dbl>, activity_73 <dbl>, activity_74 <dbl>,
    ## #   activity_75 <dbl>, activity_76 <dbl>, activity_77 <dbl>,
    ## #   activity_78 <dbl>, activity_79 <dbl>, activity_80 <dbl>,
    ## #   activity_81 <dbl>, activity_82 <dbl>, activity_83 <dbl>,
    ## #   activity_84 <dbl>, activity_85 <dbl>, activity_86 <dbl>,
    ## #   activity_87 <dbl>, activity_88 <dbl>, activity_89 <dbl>,
    ## #   activity_90 <dbl>, activity_91 <dbl>, activity_92 <dbl>,
    ## #   activity_93 <dbl>, activity_94 <dbl>, activity_95 <dbl>,
    ## #   activity_96 <dbl>, activity_97 <dbl>, activity_98 <dbl>,
    ## #   activity_99 <dbl>, activity_100 <dbl>, activity_101 <dbl>,
    ## #   activity_102 <dbl>, activity_103 <dbl>, activity_104 <dbl>, …
